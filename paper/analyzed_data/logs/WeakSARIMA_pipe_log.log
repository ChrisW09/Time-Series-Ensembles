
=========================================
== Pipeline Step 1: Data Preprocessing ==
=========================================

Searching time information...
Dates found in 'index' column!
Inferred frequency: month start
Data goes from 2004-01 to 2023-12, resulting in 240 observations.

Selecting target and covariates...
Target: WeakSARIMA
Covariates: None

Data Insights:
         WeakSARIMA
Date               
2004-01   67.834583
2004-02   67.990248
2004-03   60.532925
2004-04   60.827498
2004-05   57.793300

[Time elapsed: 04m 28s]


=====================================================
== Pipeline Step 2: Individual Models' Predictions ==
=====================================================

Splitting data for training of forecasters (train/test ratio: 30/70)...
Initial training set has 72 observations and goes from 2004-01 to 2009-12.

In an historical expanding window approach, there are 168 periods to be forecasted by the individual models: 2010-01 to 2023-12
Out-of-sample predictions are generated for next period: 2024-01

Now generating 168 one-step ahead historical expanding window predictions from model: Naive (sktime)
Performing out-of-sample predictions...
...finished!

Now generating 168 one-step ahead historical expanding window predictions from model: STL (sktime)
Performing out-of-sample predictions...
...finished!

Now generating 168 one-step ahead historical expanding window predictions from model: XGBoost (darts)
Now performing corresponding out-of-sample predictions...
...finished!

Skipping covariate forecasters since no covariates are given.

Finished predictions of individual forecasters!

Insights into forecasters' historical predictions:
             Naive        STL    XGBoost
Date                                    
2010-01  54.125598  54.909797  53.260006
2010-02  54.391598  59.503070  49.700474
2010-03  55.414677  54.191112  53.145664
2010-04  57.505825  52.546657  56.468643
2010-05  54.400890  50.757380  49.862255

Insights into forecasters' future predictions:
           Naive        STL    XGBoost
Date                                  
2024-01  80.9192  83.754654  82.660751

[Time elapsed: 05m 41s]


===================================================
== Pipeline Step 3: Ensemble Models' Predictions ==
===================================================

Splitting individual forecast data (n = 168) for training of ensemblers (train/test ratio: 25/75)...
Initial training set has 42 observations and goes from 2010-01 to 2013-06

In an historical expanding window approach, there are 126 periods to be forecasted by the ensemble models: 2013-07 to 2023-12
Out-of-sample predictions are generated for next period: 2023-12-31 00:00:00

Now generating 126 one-step ahead historical expanding window predictions from ensemble model: 'Weighted - Simple'
...Forecast 1 / 126
...Forecast 32 / 126
...Forecast 63 / 126
...Forecast 95 / 126
...finished!
Performing out-of-sample predictions...
...finished!

Now generating 126 one-step ahead historical expanding window predictions from ensemble model: 'Weighted - Inverse RMSE'
...Forecast 1 / 126
...Forecast 32 / 126
...Forecast 63 / 126
...Forecast 95 / 126
...finished!
Performing out-of-sample predictions...
...finished!

Finished predictions of ensemble forecasters!

Insights into ensemblers' historical predictions:
         Weighted Ensemble: Simple  Weighted Ensemble: Inverse RMSE
2013-07                  67.212819                        67.309768
2013-08                  63.423486                        63.684959
2013-09                  64.322448                        64.162340
2013-10                  59.903556                        60.138527
2013-11                  60.161225                        60.276926

Insights into ensemblers' future predictions:
         Weighted Ensemble: Simple  Weighted Ensemble: Inverse RMSE
Date                                                               
2024-01                   82.44487                        82.304688

Merging...
...finished!


[Time elapsed: 05m 42s]


==============================================================
== Pipeline Step 4: Ranking Models' Predictive Performance ==
==============================================================

Calculating MAPE, RMSE, sMAPE per model...
Ranking models ...
...finished!

Results:
                                     MAPE      RMSE     sMAPE  MAPE Ranking  \
Model                                                                         
Weighted Ensemble: Inverse RMSE  0.030578  2.735334  2.041507             1   
Weighted Ensemble: Simple        0.030788  2.762546  2.055893             2   
Naive                            0.032951  2.791199  2.194743             3   
XGBoost                          0.034701  3.180757  2.328224             4   
STL                              0.044823  3.999710  2.979882             5   

                                 RMSE Ranking  sMAPE Ranking  
Model                                                         
Weighted Ensemble: Inverse RMSE             1              1  
Weighted Ensemble: Simple                   2              2  
Naive                                       3              3  
XGBoost                                     4              4  
STL                                         5              5  

The 'Weighted Ensemble: Inverse RMSE' is identified as the best model based on the MAPE value of its the historical predictions.
Thus, it is recommended to work with the future predictions coming from this model:
Date
2024-01    82.304688
Freq: M, Name: Weighted Ensemble: Inverse RMSE, dtype: float64

[2024-03-10 08:35] Finished Pipeline  for WeakSARIMA!
[Total time elapsed: 05m 42s]
=================================================================================

