{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interface for Pipeline Execution \n",
    "## (Simulated Data from SARIMAX Process)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1) Import Models, Metrics, Paths, and Functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading paths...\n",
      "Loading helper functions...\n",
      "Loading data transformers...\n",
      "Loading models...\n",
      "Loading metrics...\n"
     ]
    }
   ],
   "source": [
    "from utils.helpers import csv_reader\n",
    "from utils.paths import *\n",
    "from pipeline.run_pipeline import run_pipeline\n",
    "\n",
    "\n",
    "from models import MODELS\n",
    "from metrics import METRICS\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-07T02:03:15.179866Z",
     "start_time": "2024-03-07T02:02:54.429234Z"
    }
   },
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# print(METRICS)\n",
    "# print(MODELS)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-07T02:03:15.188538Z",
     "start_time": "2024-03-07T02:03:15.182876Z"
    }
   },
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2) Select Input Data "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-07T02:03:15.215902Z",
     "start_time": "2024-03-07T02:03:15.191556Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    y          x1         x2          x3\n",
      "Date                                                    \n",
      "2004-01-01  50.840469  427.595799  55.337904  900.325291\n",
      "2004-02-01  52.871538  434.062163  54.959155  900.775888\n",
      "2004-03-01  53.769316  453.264284  56.470633  899.510058\n",
      "2004-04-01  57.672973  459.367523  56.704233  903.524834\n",
      "2004-05-01  57.182051  462.354356  61.557907  905.071762\n"
     ]
    }
   ],
   "source": [
    "# Read input data\n",
    "df = csv_reader(SIMDATA_DIR, 'noisy_simdata')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# ## Using the EUR-USD Exchange Rate data\n",
    "# \n",
    "# df = csv_reader(TESTDATA_DIR, 'eurusd', columns=['datetime', 'bid_close'])\n",
    "# import sys\n",
    "# import warnings\n",
    "# # warnings( sys.__stdout__())\n",
    "# \n",
    "# #sys.jupyter_stdout = sys.__stdout__\n",
    "# print(\"hey\")\n",
    "# print(df.head())\n",
    "# \n",
    "# # For testng pipeline for now I use a small subset:\n",
    "# df = df.iloc[:10000, :]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-07T02:03:15.226876Z",
     "start_time": "2024-03-07T02:03:15.220919Z"
    }
   },
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3) Run Pipeline \n",
    "##    ... on Simulated Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[33;1m=================================================================================\n",
      "[2024-03-07 03:03] Starting  Pipeline...\u001B[0m\n",
      "\u001B[33;1m\n",
      "=========================================\n",
      "== Pipeline Step 1: Data Preprocessing ==\n",
      "=========================================\n",
      "\u001B[0m\n",
      "\u001B[33;1mSearching for time information...\u001B[0m\n",
      "\u001B[33;1mDates found in 'index' column!\u001B[0m\n",
      "\u001B[33;1mInferred frequency: month start\u001B[0m\n",
      "\u001B[33;1mData from goes from 2004-01-01 to 2013-12-01, resulting in 120 observations.\n",
      "\u001B[0m\n",
      "\u001B[33;1mSelecting target and covariates...\u001B[0m\n",
      "\u001B[33;1mTarget: y\u001B[0m\n",
      "\u001B[33;1mCovariates: x1, x2, x3\u001B[0m\n",
      "\u001B[33;1m\n",
      "Data Insight:\n",
      "\u001B[0m\n",
      "\u001B[33;1m                    y          x1         x2          x3\n",
      "Date                                                    \n",
      "2004-01-01  50.840469  427.595799  55.337904  900.325291\n",
      "2004-02-01  52.871538  434.062163  54.959155  900.775888\n",
      "2004-03-01  53.769316  453.264284  56.470633  899.510058\n",
      "2004-04-01  57.672973  459.367523  56.704233  903.524834\n",
      "2004-05-01  57.182051  462.354356  61.557907  905.071762\u001B[0m\n",
      "\u001B[33;1m[Time elapsed: 00s]\n",
      "\u001B[0m\n",
      "\u001B[33;1m\n",
      "=====================================================\n",
      "== Pipeline Step 2: Individual Models' Predictions ==\n",
      "=====================================================\n",
      "\u001B[0m\n",
      "\u001B[33;1mSplitting data (train/test ratio: 30/70)...\n",
      "Initial training set has 36 observations and goes from 2004-01-01 to 2006-12-01.\n",
      "There are 84 periods to be forecasted: 2007-01-01 to 2013-12-01\n",
      "\u001B[0m\n",
      "\u001B[33;1mNow generating 84 one-step ahead expanding window predictions from model: Naive (sktime)\u001B[0m\n",
      "\u001B[33;1m...finished!\n",
      "\u001B[0m\n",
      "\u001B[33;1mNow generating 84 one-step ahead expanding window predictions from model: Naive (drift) (sktime)\u001B[0m\n",
      "\u001B[33;1m...finished!\n",
      "\u001B[0m\n",
      "\u001B[33;1mNow generating 84 one-step ahead expanding window predictions from model: AutoSARIMA (sktime)\u001B[0m\n",
      "\u001B[33;1mAuto-fitting model. Refitting every 28th period.\u001B[0m\n",
      "\u001B[33;1mAutoSARIMA forecast 1 / 84\u001B[0m\n",
      "\u001B[33;1mAutoSARIMA forecast 17 / 84\u001B[0m\n",
      "\u001B[33;1mAutoSARIMA forecast 34 / 84\u001B[0m\n",
      "\u001B[33;1mAutoSARIMA forecast 51 / 84\u001B[0m\n",
      "\u001B[33;1mAutoSARIMA forecast 68 / 84\u001B[0m\n",
      "\u001B[33;1mAutoSARIMA forecast 84 / 84\u001B[0m\n",
      "\u001B[33;1m...finished!\n",
      "\u001B[0m\n",
      "\u001B[33;1mNow generating 84 one-step ahead expanding window predictions from model: Exponential Smoothing (sktime)\u001B[0m\n",
      "\u001B[33;1m...finished!\n",
      "\u001B[0m\n",
      "\u001B[33;1mNow generating 84 one-step ahead expanding window predictions from model: STL (sktime)\u001B[0m\n",
      "\u001B[33;1m...finished!\n",
      "\u001B[0m\n",
      "\u001B[33;1mNow generating 84 one-step ahead expanding window predictions from model: XGBoost (darts)\u001B[0m\n",
      "\u001B[33;1m...finished!\n",
      "\u001B[0m\n",
      "\u001B[33;1mNow generating 84 one-step ahead expanding window predictions from model: XGBoost with covariates (darts)\u001B[0m\n",
      "\u001B[33;1m...finished!\n",
      "\u001B[0m\n",
      "\u001B[33;1m\n",
      "Individual forecasters' predictions finished!\n",
      "\n",
      "Insights into forecasters' predictions:\u001B[0m\n",
      "\u001B[33;1m             Naive  Naive (drift)  AutoSARIMA  Exponential Smoothing  \\\n",
      "Date                                                                   \n",
      "2007-01  48.857243      48.800580   49.606623              49.016606   \n",
      "2007-02  48.254157      48.182315   48.515764              48.500499   \n",
      "2007-03  47.765006      47.681886   47.973535              48.001824   \n",
      "2007-04  46.394433      46.277432   46.969779              46.904911   \n",
      "2007-05  44.212976      44.043041   45.108821              45.025232   \n",
      "\n",
      "               STL    XGBoost  XGBoost with covariates  \n",
      "Date                                                    \n",
      "2007-01  40.574201  48.632446                49.624989  \n",
      "2007-02  41.374739  50.458118                49.453224  \n",
      "2007-03  45.653502  47.823650                48.497398  \n",
      "2007-04  41.569708  47.594688                48.059471  \n",
      "2007-05  49.855823  48.784794                45.706074  \u001B[0m\n",
      "\u001B[33;1m\n",
      "\u001B[0m\n",
      "\u001B[33;1mExporting individual predictions to csv file...\u001B[0m\n",
      "\u001B[33;1m...finished!\n",
      "\u001B[0m\n",
      "\u001B[33;1m[Time elapsed: 57s]\n",
      "\u001B[0m\n",
      "\u001B[33;1m\n",
      "====================================================\n",
      "== Pipeline Step 3: Ensemble Models' Predictions ==\n",
      "====================================================\n",
      "\u001B[0m\n",
      "\u001B[33;1mSplitting forecast data (n = 84) for ensemble forecasts (train/test ratio: 25/75)...\u001B[0m\n",
      "\u001B[33;1mInitial training set has 21 observations and goes from 2007-01 to 2008-09\u001B[0m\n",
      "\u001B[33;1mThere are 63 periods to be forecasted by the individual models 2008-10 to 2013-12\u001B[0m\n",
      "\u001B[33;1m\n",
      "Now generating 63 one-step ahead expanding window predictions from ensemble model: 'Weighted - Simple'\u001B[0m\n",
      "\u001B[33;1mEnsemble forecast 1 / 63\u001B[0m\n",
      "\u001B[33;1mEnsemble forecast 13 / 63\u001B[0m\n",
      "\u001B[33;1mEnsemble forecast 26 / 63\u001B[0m\n",
      "\u001B[33;1mEnsemble forecast 38 / 63\u001B[0m\n",
      "\u001B[33;1mEnsemble forecast 51 / 63\u001B[0m\n",
      "\u001B[33;1mEnsemble forecast 63 / 63\u001B[0m\n",
      "\u001B[33;1m...finished!\u001B[0m\n",
      "\u001B[33;1m\n",
      "Now generating 63 one-step ahead expanding window predictions from ensemble model: 'Weighted - Inverse RMSE'\u001B[0m\n",
      "\u001B[33;1mEnsemble forecast 1 / 63\u001B[0m\n",
      "\u001B[33;1mEnsemble forecast 13 / 63\u001B[0m\n",
      "\u001B[33;1mEnsemble forecast 26 / 63\u001B[0m\n",
      "\u001B[33;1mEnsemble forecast 38 / 63\u001B[0m\n",
      "\u001B[33;1mEnsemble forecast 51 / 63\u001B[0m\n",
      "\u001B[33;1mEnsemble forecast 63 / 63\u001B[0m\n",
      "\u001B[33;1m...finished!\u001B[0m\n",
      "\u001B[33;1m\n",
      "Now generating 63 one-step ahead expanding window predictions from ensemble model: 'Weighted - Inverse Variance'\u001B[0m\n",
      "\u001B[33;1mEnsemble forecast 1 / 63\u001B[0m\n",
      "\u001B[33;1mEnsemble forecast 13 / 63\u001B[0m\n",
      "\u001B[33;1mEnsemble forecast 26 / 63\u001B[0m\n",
      "\u001B[33;1mEnsemble forecast 38 / 63\u001B[0m\n",
      "\u001B[33;1mEnsemble forecast 51 / 63\u001B[0m\n",
      "\u001B[33;1mEnsemble forecast 63 / 63\u001B[0m\n",
      "\u001B[33;1m...finished!\u001B[0m\n",
      "\u001B[33;1m\n",
      "Now generating 63 one-step ahead expanding window predictions from ensemble model: 'Weighted - Inverse Error Covariance'\u001B[0m\n",
      "\u001B[33;1mEnsemble forecast 1 / 63\u001B[0m\n",
      "\u001B[33;1mEnsemble forecast 13 / 63\u001B[0m\n",
      "\u001B[33;1mEnsemble forecast 26 / 63\u001B[0m\n",
      "\u001B[33;1mEnsemble forecast 38 / 63\u001B[0m\n",
      "\u001B[33;1mEnsemble forecast 51 / 63\u001B[0m\n",
      "\u001B[33;1mEnsemble forecast 63 / 63\u001B[0m\n",
      "\u001B[33;1m...finished!\u001B[0m\n",
      "\u001B[33;1m\n",
      "Now generating 63 one-step ahead expanding window predictions from ensemble model: 'Meta - SVR (sklearn)'\u001B[0m\n",
      "\u001B[33;1mEnsemble forecast 1 / 63\u001B[0m\n",
      "\u001B[33;1mEnsemble forecast 13 / 63\u001B[0m\n",
      "\u001B[33;1mEnsemble forecast 26 / 63\u001B[0m\n",
      "\u001B[33;1mEnsemble forecast 38 / 63\u001B[0m\n",
      "\u001B[33;1mEnsemble forecast 51 / 63\u001B[0m\n",
      "\u001B[33;1mEnsemble forecast 63 / 63\u001B[0m\n",
      "\u001B[33;1m...finished!\u001B[0m\n",
      "\u001B[33;1m\n",
      "Now generating 63 one-step ahead expanding window predictions from ensemble model: 'Meta - Ridge (sklearn)'\u001B[0m\n",
      "\u001B[33;1mEnsemble forecast 1 / 63\u001B[0m\n",
      "\u001B[33;1mEnsemble forecast 13 / 63\u001B[0m\n",
      "\u001B[33;1mEnsemble forecast 26 / 63\u001B[0m\n",
      "\u001B[33;1mEnsemble forecast 38 / 63\u001B[0m\n",
      "\u001B[33;1mEnsemble forecast 51 / 63\u001B[0m\n",
      "\u001B[33;1mEnsemble forecast 63 / 63\u001B[0m\n",
      "\u001B[33;1m...finished!\u001B[0m\n",
      "\u001B[33;1m\n",
      "Now generating 63 one-step ahead expanding window predictions from ensemble model: 'Meta - Linear Regression (sklearn)'\u001B[0m\n",
      "\u001B[33;1mEnsemble forecast 1 / 63\u001B[0m\n",
      "\u001B[33;1mEnsemble forecast 13 / 63\u001B[0m\n",
      "\u001B[33;1mEnsemble forecast 26 / 63\u001B[0m\n",
      "\u001B[33;1mEnsemble forecast 38 / 63\u001B[0m\n",
      "\u001B[33;1mEnsemble forecast 51 / 63\u001B[0m\n",
      "\u001B[33;1mEnsemble forecast 63 / 63\u001B[0m\n",
      "\u001B[33;1m...finished!\u001B[0m\n",
      "\u001B[33;1m\n",
      "Now generating 63 one-step ahead expanding window predictions from ensemble model: 'Meta - MLP (sklearn)'\u001B[0m\n",
      "\u001B[33;1mEnsemble forecast 1 / 63\u001B[0m\n",
      "\u001B[33;1mEnsemble forecast 13 / 63\u001B[0m\n",
      "\u001B[33;1mEnsemble forecast 26 / 63\u001B[0m\n",
      "\u001B[33;1mEnsemble forecast 38 / 63\u001B[0m\n",
      "\u001B[33;1mEnsemble forecast 51 / 63\u001B[0m\n",
      "\u001B[33;1mEnsemble forecast 63 / 63\u001B[0m\n",
      "\u001B[33;1m...finished!\u001B[0m\n",
      "\u001B[33;1m\n",
      "Now generating 63 one-step ahead expanding window predictions from ensemble model: 'Meta - RandomForest (sklearn)'\u001B[0m\n",
      "\u001B[33;1mEnsemble forecast 1 / 63\u001B[0m\n",
      "\u001B[33;1mEnsemble forecast 13 / 63\u001B[0m\n",
      "\u001B[33;1mEnsemble forecast 26 / 63\u001B[0m\n",
      "\u001B[33;1mEnsemble forecast 38 / 63\u001B[0m\n",
      "\u001B[33;1mEnsemble forecast 51 / 63\u001B[0m\n",
      "\u001B[33;1mEnsemble forecast 63 / 63\u001B[0m\n",
      "\u001B[33;1m...finished!\u001B[0m\n",
      "\u001B[33;1m\n",
      "Ensemble predictions finished!\n",
      "\n",
      "Insights into ensembles' predictions:\u001B[0m\n",
      "\u001B[33;1m         Weighted Ensemble: Simple  Weighted Ensemble: Inverse RMSE  \\\n",
      "2008-10                  58.005342                        58.338293   \n",
      "2008-11                  58.081381                        57.641110   \n",
      "2008-12                  58.691317                        58.591677   \n",
      "2009-01                  60.397148                        60.517525   \n",
      "2009-02                  61.113299                        60.814867   \n",
      "\n",
      "         Weighted Ensemble: Inverse Variance  \\\n",
      "2008-10                            57.729481   \n",
      "2008-11                            58.429848   \n",
      "2008-12                            58.537898   \n",
      "2009-01                            60.000398   \n",
      "2009-02                            60.891558   \n",
      "\n",
      "         Weighted Ensemble: Inverse Error Covariance  Meta Ensemble: SVR  \\\n",
      "2008-10                                    59.429356           62.201439   \n",
      "2008-11                                    59.823373           61.395111   \n",
      "2008-12                                    59.109602           60.441724   \n",
      "2009-01                                    63.167688           63.756406   \n",
      "2009-02                                    63.054764           64.408891   \n",
      "\n",
      "         Meta Ensemble: Ridge  Meta Ensemble: Linear Regression  \\\n",
      "2008-10             60.966560                         57.055146   \n",
      "2008-11             58.693008                         62.008223   \n",
      "2008-12             60.361155                         58.875037   \n",
      "2009-01             63.877170                         60.134848   \n",
      "2009-02             62.597588                         59.901068   \n",
      "\n",
      "         Meta Ensemble: MLP  Meta Ensemble: RandomForest  \n",
      "2008-10           76.763095                    58.307169  \n",
      "2008-11           66.517875                    57.801584  \n",
      "2008-12           62.299776                    57.763094  \n",
      "2009-01           74.890103                    60.104125  \n",
      "2009-02           78.589445                    60.072025  \u001B[0m\n",
      "\u001B[33;1m\n",
      "Merging...\u001B[0m\n",
      "\u001B[33;1m...finished!\n",
      "\u001B[0m\n",
      "\u001B[33;1mExporting ensemble predictions to csv file...\u001B[0m\n",
      "\u001B[33;1mExporting full predictions to csv file...\u001B[0m\n",
      "\u001B[33;1m...finished!\n",
      "\u001B[0m\n",
      "\u001B[33;1m[Time elapsed: 01m 13s]\n",
      "\u001B[0m\n",
      "\u001B[33;1m\n",
      "==============================================================\n",
      "== Pipeline Step 4: Ranking Models' Predictive Performance ==\n",
      "==============================================================\n",
      "\u001B[0m\n",
      "\u001B[33;1mCalculating MAE, RMSE, MAPE, sMAPE per model...\u001B[0m\n",
      "\u001B[33;1mRanking forecasters ...\u001B[0m\n",
      "\u001B[33;1m...finished!\n",
      "\u001B[0m\n",
      "\u001B[33;1mExporting metrics ranking to csv file...\u001B[0m\n",
      "\u001B[33;1m...finished!\n",
      "\u001B[0m\n",
      "\u001B[33;1mResults:\u001B[0m\n",
      "\u001B[33;1m                                          Model        MAE       RMSE  \\\n",
      "0                     Weighted Ensemble: Simple   1.961156   2.594782   \n",
      "1           Weighted Ensemble: Inverse Variance   1.966691   2.595708   \n",
      "2               Weighted Ensemble: Inverse RMSE   1.962414   2.578586   \n",
      "3                         Exponential Smoothing   2.059355   2.667917   \n",
      "4                                    AutoSARIMA   2.087225   2.688896   \n",
      "5                                         Naive   2.094541   2.717243   \n",
      "6                                 Naive (drift)   2.121582   2.717872   \n",
      "7                   Meta Ensemble: RandomForest   2.194736   2.771463   \n",
      "8                          Meta Ensemble: Ridge   2.216565   2.882020   \n",
      "9   Weighted Ensemble: Inverse Error Covariance   2.233037   2.958330   \n",
      "10                      XGBoost with covariates   2.322688   3.146786   \n",
      "11                           Meta Ensemble: SVR   2.320089   2.969596   \n",
      "12                                      XGBoost   2.313007   3.070661   \n",
      "13             Meta Ensemble: Linear Regression   2.361680   3.106995   \n",
      "14                                          STL   3.435032   4.510927   \n",
      "15                           Meta Ensemble: MLP  12.996535  15.284381   \n",
      "\n",
      "        MAPE      sMAPE  MAE Ranking  RMSE Ranking  MAPE Ranking  \\\n",
      "0   0.027420   1.839140            1             2             1   \n",
      "1   0.027491   1.844966            3             3             2   \n",
      "2   0.027491   1.843975            2             1             3   \n",
      "3   0.028848   1.933606            4             4             4   \n",
      "4   0.029154   1.952686            5             5             5   \n",
      "5   0.029453   1.972192            6             6             6   \n",
      "6   0.029849   1.994633            7             7             7   \n",
      "7   0.030667   2.057694            8             8             8   \n",
      "8   0.031265   2.087496            9             9             9   \n",
      "9   0.031425   2.103188           10            10            10   \n",
      "10  0.032399   2.188361           13            14            11   \n",
      "11  0.032986   2.198613           12            11            12   \n",
      "12  0.033173   2.244724           11            12            13   \n",
      "13  0.033410   2.247111           14            13            14   \n",
      "14  0.048180   3.200819           15            15            15   \n",
      "15  0.183987  11.336418           16            16            16   \n",
      "\n",
      "    sMAPE Ranking  \n",
      "0               1  \n",
      "1               3  \n",
      "2               2  \n",
      "3               4  \n",
      "4               5  \n",
      "5               6  \n",
      "6               7  \n",
      "7               8  \n",
      "8               9  \n",
      "9              10  \n",
      "10             11  \n",
      "11             12  \n",
      "12             13  \n",
      "13             14  \n",
      "14             15  \n",
      "15             16  \u001B[0m\n",
      "\u001B[33;1m\n",
      "\n",
      "[2024-03-07 03:04] Finished Pipeline!\n",
      "[Total time elapsed: 01m 13s]\n",
      "=================================================================================\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "output_dict = run_pipeline(\n",
    "    df=df, models=MODELS, metrics=METRICS,\n",
    "    start=\"2004-01-01\", end=\"2013-12-31\",  # filtering the first 10 years of data\n",
    "    verbose=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-07T02:04:28.924866Z",
     "start_time": "2024-03-07T02:03:15.230894Z"
    }
   },
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4) Show Ranking Table"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-07T02:04:29.221219Z",
     "start_time": "2024-03-07T02:04:28.926876Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<pandas.io.formats.style.Styler at 0x21ea6955ad0>",
      "text/html": "<style type=\"text/css\">\n</style>\n<table id=\"T_a08a5\">\n  <thead>\n    <tr>\n      <th id=\"T_a08a5_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n      <th id=\"T_a08a5_level0_col1\" class=\"col_heading level0 col1\" >MAE</th>\n      <th id=\"T_a08a5_level0_col2\" class=\"col_heading level0 col2\" >RMSE</th>\n      <th id=\"T_a08a5_level0_col3\" class=\"col_heading level0 col3\" >MAPE</th>\n      <th id=\"T_a08a5_level0_col4\" class=\"col_heading level0 col4\" >sMAPE</th>\n      <th id=\"T_a08a5_level0_col5\" class=\"col_heading level0 col5\" >MAE Ranking</th>\n      <th id=\"T_a08a5_level0_col6\" class=\"col_heading level0 col6\" >RMSE Ranking</th>\n      <th id=\"T_a08a5_level0_col7\" class=\"col_heading level0 col7\" >MAPE Ranking</th>\n      <th id=\"T_a08a5_level0_col8\" class=\"col_heading level0 col8\" >sMAPE Ranking</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td id=\"T_a08a5_row0_col0\" class=\"data row0 col0\" >Weighted Ensemble: Simple</td>\n      <td id=\"T_a08a5_row0_col1\" class=\"data row0 col1\" >1.961</td>\n      <td id=\"T_a08a5_row0_col2\" class=\"data row0 col2\" >2.595</td>\n      <td id=\"T_a08a5_row0_col3\" class=\"data row0 col3\" >0.027</td>\n      <td id=\"T_a08a5_row0_col4\" class=\"data row0 col4\" >1.839</td>\n      <td id=\"T_a08a5_row0_col5\" class=\"data row0 col5\" >1</td>\n      <td id=\"T_a08a5_row0_col6\" class=\"data row0 col6\" >2</td>\n      <td id=\"T_a08a5_row0_col7\" class=\"data row0 col7\" >1</td>\n      <td id=\"T_a08a5_row0_col8\" class=\"data row0 col8\" >1</td>\n    </tr>\n    <tr>\n      <td id=\"T_a08a5_row1_col0\" class=\"data row1 col0\" >Weighted Ensemble: Inverse Variance</td>\n      <td id=\"T_a08a5_row1_col1\" class=\"data row1 col1\" >1.967</td>\n      <td id=\"T_a08a5_row1_col2\" class=\"data row1 col2\" >2.596</td>\n      <td id=\"T_a08a5_row1_col3\" class=\"data row1 col3\" >0.027</td>\n      <td id=\"T_a08a5_row1_col4\" class=\"data row1 col4\" >1.845</td>\n      <td id=\"T_a08a5_row1_col5\" class=\"data row1 col5\" >3</td>\n      <td id=\"T_a08a5_row1_col6\" class=\"data row1 col6\" >3</td>\n      <td id=\"T_a08a5_row1_col7\" class=\"data row1 col7\" >2</td>\n      <td id=\"T_a08a5_row1_col8\" class=\"data row1 col8\" >3</td>\n    </tr>\n    <tr>\n      <td id=\"T_a08a5_row2_col0\" class=\"data row2 col0\" >Weighted Ensemble: Inverse RMSE</td>\n      <td id=\"T_a08a5_row2_col1\" class=\"data row2 col1\" >1.962</td>\n      <td id=\"T_a08a5_row2_col2\" class=\"data row2 col2\" >2.579</td>\n      <td id=\"T_a08a5_row2_col3\" class=\"data row2 col3\" >0.027</td>\n      <td id=\"T_a08a5_row2_col4\" class=\"data row2 col4\" >1.844</td>\n      <td id=\"T_a08a5_row2_col5\" class=\"data row2 col5\" >2</td>\n      <td id=\"T_a08a5_row2_col6\" class=\"data row2 col6\" >1</td>\n      <td id=\"T_a08a5_row2_col7\" class=\"data row2 col7\" >3</td>\n      <td id=\"T_a08a5_row2_col8\" class=\"data row2 col8\" >2</td>\n    </tr>\n    <tr>\n      <td id=\"T_a08a5_row3_col0\" class=\"data row3 col0\" >Exponential Smoothing</td>\n      <td id=\"T_a08a5_row3_col1\" class=\"data row3 col1\" >2.059</td>\n      <td id=\"T_a08a5_row3_col2\" class=\"data row3 col2\" >2.668</td>\n      <td id=\"T_a08a5_row3_col3\" class=\"data row3 col3\" >0.029</td>\n      <td id=\"T_a08a5_row3_col4\" class=\"data row3 col4\" >1.934</td>\n      <td id=\"T_a08a5_row3_col5\" class=\"data row3 col5\" >4</td>\n      <td id=\"T_a08a5_row3_col6\" class=\"data row3 col6\" >4</td>\n      <td id=\"T_a08a5_row3_col7\" class=\"data row3 col7\" >4</td>\n      <td id=\"T_a08a5_row3_col8\" class=\"data row3 col8\" >4</td>\n    </tr>\n    <tr>\n      <td id=\"T_a08a5_row4_col0\" class=\"data row4 col0\" >AutoSARIMA</td>\n      <td id=\"T_a08a5_row4_col1\" class=\"data row4 col1\" >2.087</td>\n      <td id=\"T_a08a5_row4_col2\" class=\"data row4 col2\" >2.689</td>\n      <td id=\"T_a08a5_row4_col3\" class=\"data row4 col3\" >0.029</td>\n      <td id=\"T_a08a5_row4_col4\" class=\"data row4 col4\" >1.953</td>\n      <td id=\"T_a08a5_row4_col5\" class=\"data row4 col5\" >5</td>\n      <td id=\"T_a08a5_row4_col6\" class=\"data row4 col6\" >5</td>\n      <td id=\"T_a08a5_row4_col7\" class=\"data row4 col7\" >5</td>\n      <td id=\"T_a08a5_row4_col8\" class=\"data row4 col8\" >5</td>\n    </tr>\n    <tr>\n      <td id=\"T_a08a5_row5_col0\" class=\"data row5 col0\" >Naive</td>\n      <td id=\"T_a08a5_row5_col1\" class=\"data row5 col1\" >2.095</td>\n      <td id=\"T_a08a5_row5_col2\" class=\"data row5 col2\" >2.717</td>\n      <td id=\"T_a08a5_row5_col3\" class=\"data row5 col3\" >0.029</td>\n      <td id=\"T_a08a5_row5_col4\" class=\"data row5 col4\" >1.972</td>\n      <td id=\"T_a08a5_row5_col5\" class=\"data row5 col5\" >6</td>\n      <td id=\"T_a08a5_row5_col6\" class=\"data row5 col6\" >6</td>\n      <td id=\"T_a08a5_row5_col7\" class=\"data row5 col7\" >6</td>\n      <td id=\"T_a08a5_row5_col8\" class=\"data row5 col8\" >6</td>\n    </tr>\n    <tr>\n      <td id=\"T_a08a5_row6_col0\" class=\"data row6 col0\" >Naive (drift)</td>\n      <td id=\"T_a08a5_row6_col1\" class=\"data row6 col1\" >2.122</td>\n      <td id=\"T_a08a5_row6_col2\" class=\"data row6 col2\" >2.718</td>\n      <td id=\"T_a08a5_row6_col3\" class=\"data row6 col3\" >0.030</td>\n      <td id=\"T_a08a5_row6_col4\" class=\"data row6 col4\" >1.995</td>\n      <td id=\"T_a08a5_row6_col5\" class=\"data row6 col5\" >7</td>\n      <td id=\"T_a08a5_row6_col6\" class=\"data row6 col6\" >7</td>\n      <td id=\"T_a08a5_row6_col7\" class=\"data row6 col7\" >7</td>\n      <td id=\"T_a08a5_row6_col8\" class=\"data row6 col8\" >7</td>\n    </tr>\n    <tr>\n      <td id=\"T_a08a5_row7_col0\" class=\"data row7 col0\" >Meta Ensemble: RandomForest</td>\n      <td id=\"T_a08a5_row7_col1\" class=\"data row7 col1\" >2.195</td>\n      <td id=\"T_a08a5_row7_col2\" class=\"data row7 col2\" >2.771</td>\n      <td id=\"T_a08a5_row7_col3\" class=\"data row7 col3\" >0.031</td>\n      <td id=\"T_a08a5_row7_col4\" class=\"data row7 col4\" >2.058</td>\n      <td id=\"T_a08a5_row7_col5\" class=\"data row7 col5\" >8</td>\n      <td id=\"T_a08a5_row7_col6\" class=\"data row7 col6\" >8</td>\n      <td id=\"T_a08a5_row7_col7\" class=\"data row7 col7\" >8</td>\n      <td id=\"T_a08a5_row7_col8\" class=\"data row7 col8\" >8</td>\n    </tr>\n    <tr>\n      <td id=\"T_a08a5_row8_col0\" class=\"data row8 col0\" >Meta Ensemble: Ridge</td>\n      <td id=\"T_a08a5_row8_col1\" class=\"data row8 col1\" >2.217</td>\n      <td id=\"T_a08a5_row8_col2\" class=\"data row8 col2\" >2.882</td>\n      <td id=\"T_a08a5_row8_col3\" class=\"data row8 col3\" >0.031</td>\n      <td id=\"T_a08a5_row8_col4\" class=\"data row8 col4\" >2.087</td>\n      <td id=\"T_a08a5_row8_col5\" class=\"data row8 col5\" >9</td>\n      <td id=\"T_a08a5_row8_col6\" class=\"data row8 col6\" >9</td>\n      <td id=\"T_a08a5_row8_col7\" class=\"data row8 col7\" >9</td>\n      <td id=\"T_a08a5_row8_col8\" class=\"data row8 col8\" >9</td>\n    </tr>\n    <tr>\n      <td id=\"T_a08a5_row9_col0\" class=\"data row9 col0\" >Weighted Ensemble: Inverse Error Covariance</td>\n      <td id=\"T_a08a5_row9_col1\" class=\"data row9 col1\" >2.233</td>\n      <td id=\"T_a08a5_row9_col2\" class=\"data row9 col2\" >2.958</td>\n      <td id=\"T_a08a5_row9_col3\" class=\"data row9 col3\" >0.031</td>\n      <td id=\"T_a08a5_row9_col4\" class=\"data row9 col4\" >2.103</td>\n      <td id=\"T_a08a5_row9_col5\" class=\"data row9 col5\" >10</td>\n      <td id=\"T_a08a5_row9_col6\" class=\"data row9 col6\" >10</td>\n      <td id=\"T_a08a5_row9_col7\" class=\"data row9 col7\" >10</td>\n      <td id=\"T_a08a5_row9_col8\" class=\"data row9 col8\" >10</td>\n    </tr>\n    <tr>\n      <td id=\"T_a08a5_row10_col0\" class=\"data row10 col0\" >XGBoost with covariates</td>\n      <td id=\"T_a08a5_row10_col1\" class=\"data row10 col1\" >2.323</td>\n      <td id=\"T_a08a5_row10_col2\" class=\"data row10 col2\" >3.147</td>\n      <td id=\"T_a08a5_row10_col3\" class=\"data row10 col3\" >0.032</td>\n      <td id=\"T_a08a5_row10_col4\" class=\"data row10 col4\" >2.188</td>\n      <td id=\"T_a08a5_row10_col5\" class=\"data row10 col5\" >13</td>\n      <td id=\"T_a08a5_row10_col6\" class=\"data row10 col6\" >14</td>\n      <td id=\"T_a08a5_row10_col7\" class=\"data row10 col7\" >11</td>\n      <td id=\"T_a08a5_row10_col8\" class=\"data row10 col8\" >11</td>\n    </tr>\n    <tr>\n      <td id=\"T_a08a5_row11_col0\" class=\"data row11 col0\" >Meta Ensemble: SVR</td>\n      <td id=\"T_a08a5_row11_col1\" class=\"data row11 col1\" >2.320</td>\n      <td id=\"T_a08a5_row11_col2\" class=\"data row11 col2\" >2.970</td>\n      <td id=\"T_a08a5_row11_col3\" class=\"data row11 col3\" >0.033</td>\n      <td id=\"T_a08a5_row11_col4\" class=\"data row11 col4\" >2.199</td>\n      <td id=\"T_a08a5_row11_col5\" class=\"data row11 col5\" >12</td>\n      <td id=\"T_a08a5_row11_col6\" class=\"data row11 col6\" >11</td>\n      <td id=\"T_a08a5_row11_col7\" class=\"data row11 col7\" >12</td>\n      <td id=\"T_a08a5_row11_col8\" class=\"data row11 col8\" >12</td>\n    </tr>\n    <tr>\n      <td id=\"T_a08a5_row12_col0\" class=\"data row12 col0\" >XGBoost</td>\n      <td id=\"T_a08a5_row12_col1\" class=\"data row12 col1\" >2.313</td>\n      <td id=\"T_a08a5_row12_col2\" class=\"data row12 col2\" >3.071</td>\n      <td id=\"T_a08a5_row12_col3\" class=\"data row12 col3\" >0.033</td>\n      <td id=\"T_a08a5_row12_col4\" class=\"data row12 col4\" >2.245</td>\n      <td id=\"T_a08a5_row12_col5\" class=\"data row12 col5\" >11</td>\n      <td id=\"T_a08a5_row12_col6\" class=\"data row12 col6\" >12</td>\n      <td id=\"T_a08a5_row12_col7\" class=\"data row12 col7\" >13</td>\n      <td id=\"T_a08a5_row12_col8\" class=\"data row12 col8\" >13</td>\n    </tr>\n    <tr>\n      <td id=\"T_a08a5_row13_col0\" class=\"data row13 col0\" >Meta Ensemble: Linear Regression</td>\n      <td id=\"T_a08a5_row13_col1\" class=\"data row13 col1\" >2.362</td>\n      <td id=\"T_a08a5_row13_col2\" class=\"data row13 col2\" >3.107</td>\n      <td id=\"T_a08a5_row13_col3\" class=\"data row13 col3\" >0.033</td>\n      <td id=\"T_a08a5_row13_col4\" class=\"data row13 col4\" >2.247</td>\n      <td id=\"T_a08a5_row13_col5\" class=\"data row13 col5\" >14</td>\n      <td id=\"T_a08a5_row13_col6\" class=\"data row13 col6\" >13</td>\n      <td id=\"T_a08a5_row13_col7\" class=\"data row13 col7\" >14</td>\n      <td id=\"T_a08a5_row13_col8\" class=\"data row13 col8\" >14</td>\n    </tr>\n    <tr>\n      <td id=\"T_a08a5_row14_col0\" class=\"data row14 col0\" >STL</td>\n      <td id=\"T_a08a5_row14_col1\" class=\"data row14 col1\" >3.435</td>\n      <td id=\"T_a08a5_row14_col2\" class=\"data row14 col2\" >4.511</td>\n      <td id=\"T_a08a5_row14_col3\" class=\"data row14 col3\" >0.048</td>\n      <td id=\"T_a08a5_row14_col4\" class=\"data row14 col4\" >3.201</td>\n      <td id=\"T_a08a5_row14_col5\" class=\"data row14 col5\" >15</td>\n      <td id=\"T_a08a5_row14_col6\" class=\"data row14 col6\" >15</td>\n      <td id=\"T_a08a5_row14_col7\" class=\"data row14 col7\" >15</td>\n      <td id=\"T_a08a5_row14_col8\" class=\"data row14 col8\" >15</td>\n    </tr>\n    <tr>\n      <td id=\"T_a08a5_row15_col0\" class=\"data row15 col0\" >Meta Ensemble: MLP</td>\n      <td id=\"T_a08a5_row15_col1\" class=\"data row15 col1\" >12.997</td>\n      <td id=\"T_a08a5_row15_col2\" class=\"data row15 col2\" >15.284</td>\n      <td id=\"T_a08a5_row15_col3\" class=\"data row15 col3\" >0.184</td>\n      <td id=\"T_a08a5_row15_col4\" class=\"data row15 col4\" >11.336</td>\n      <td id=\"T_a08a5_row15_col5\" class=\"data row15 col5\" >16</td>\n      <td id=\"T_a08a5_row15_col6\" class=\"data row15 col6\" >16</td>\n      <td id=\"T_a08a5_row15_col7\" class=\"data row15 col7\" >16</td>\n      <td id=\"T_a08a5_row15_col8\" class=\"data row15 col8\" >16</td>\n    </tr>\n  </tbody>\n</table>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "# Format performance metric values\n",
    "def format_numeric(val):\n",
    "    if isinstance(val, float):\n",
    "        return '{:.3f}'.format(val)\n",
    "    return val\n",
    "formatted_metrics = output_dict['metrics ranking'].applymap(format_numeric)\n",
    "\n",
    "display(formatted_metrics.style.hide())\n",
    "pd.reset_option('display.float_format')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
