General:
- add a small testing dataframe to test pipeline a bit faster...

=========
PIPELINE:
=========

run_pipeline():
- create timestamp folder for data storage
- create log file storing relevant information like hyperparameter settings on top, data properties, and then console output
- print total time elapsed to console and log(auch in zwischensteps)
- add all relevant input arguments from inner functions
- csv export: if True but path not defined export in working directory

pipe1_data_preprocessing():
- everything
- make generic for daily  data etc.

pipe2_individual_forecasts():
- docstring, comments fehlen noch
- # Todo: check if SARIMAX loop takes updated params (trace = True)
- make more generic for all models that have fit and predict method; consider removing historical forecast method etc => as in arima

pipe3_ensemble_forecasts():
- comment, docstring 
- streamlining

pipe4_metrics_ranking():
- streamline code
- use pauls mse and mape functions


=========
Interface
=========
run_pipeline.ipynb:
- # monthly in print durch if bedingung ersetzen, welche df.index.freq erkennt
